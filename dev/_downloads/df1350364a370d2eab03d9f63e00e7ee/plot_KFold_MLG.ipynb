{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n================================================================================================\nK-Fold classification on the ENZYMES dataset using the approximate Multiscale Laplacian kernel.\n================================================================================================\n\nAn example plot of :class:`grakel.GraphKernel`, :class:`grakel.MultiscaleLaplacianFast`\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from __future__ import print_function\nprint(__doc__)\n\nimport argparse\n\nfrom grakel import GraphKernel\nfrom grakel import datasets\n\n# Create an argument parser for the installer of pynauty\nparser = argparse.ArgumentParser(\n    description='Measuring classification accuracy '\n                ' on multiscale_laplacian_fast')\n\nparser.add_argument(\n    '--dataset',\n    help='chose the datset you want the tests to be executed',\n    type=str,\n    default=\"ENZYMES\",\n)\n\n# Get the dataset name\ndataset_name = parser.parse_args().dataset\n\n# Check the dataset provided by the user\ndinfo = datasets.get_dataset_info(dataset_name)\nif dinfo is None:\n    raise ValueError('Dataset not found!')\nelif not dinfo[\"nl\"]:\n    raise TypeError('Dataset must have contain node attributes.')\n\n\n# The baseline dataset for node/edge-attributes\ndataset_attr = datasets.fetch_dataset(dataset_name,\n                                      with_classes=True,\n                                      prefer_attr_nodes=False,\n                                      prefer_attr_edges=False,\n                                      verbose=True)\n\nimport numpy as np\n\nfrom tqdm import tqdm\nfrom time import time\n\nfrom six import itervalues, iteritems\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn import svm\n\ndef sec_to_time(sec):\n    \"\"\"Print time in a correct format.\"\"\"\n    dt = list()\n    days = int(sec // 86400)\n    if days > 0:\n        sec -= 86400*days\n        dt.append(str(days) + \" d\")\n\n    hrs = int(sec // 3600)\n    if hrs > 0:\n        sec -= 3600*hrs\n        dt.append(str(hrs) + \" h\")\n\n    mins = int(sec // 60)\n    if mins > 0:\n        sec -= 60*mins\n        dt.append(str(mins) + \" m\")\n\n    if sec > 0:\n        dt.append(str(round(sec, 2)) + \" s\")\n    return \" \".join(dt)\n\ndef to_one_hot(G):\n    # Index all discrete labels\n    mp = {dl: i for (i, dl) in enumerate(set(l for g in G for l in itervalues(g[1])))}\n    def make_vec(k):\n        vec = np.zeros((len(mp),), dtype=float)\n        vec[k] = 1.0\n        return vec\n    return [(g[0], {i: make_vec(mp[k]) for (i, k) in iteritems(g[1])}) for g in G]\n\n# Loads the Mutag dataset from:\n# https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets\n# the biggest collection of benchmark datasets for graph_kernels.\nG, y = to_one_hot(dataset_attr.data), dataset_attr.target\nC_grid = (10. ** np.arange(4, 10, 1) / len(G)).tolist()\n\nstats = {\"acc\": list(), \"time\": list()}\nkf = KFold(n_splits=10, random_state=42, shuffle=True)\nniter = kf.get_n_splits(y)\n\nfor train_index, test_index in tqdm(kf.split(G, y),\n                                    total=niter):\n    # Train-test split of graph data\n    tri = train_index.tolist()\n    tei = test_index.tolist()\n\n    G_train, G_test = list(), list()\n    y_train, y_test = list(), list()\n    for (i, (g, t)) in enumerate(zip(G, y)):\n        if len(tri) and i == tri[0]:\n            G_train.append(g)\n            y_train.append(t)\n            tri.pop(0)\n        elif len(tei) and i == tei[0]:\n            G_test.append(g)\n            y_test.append(t)\n            tei.pop(0)\n\n    start = time()\n    gk = GraphKernel(kernel={\"name\": \"multiscale_laplacian\",\n                             \"which\": \"fast\",\n                             \"L\": 1,\n                             \"P\": 10,\n                             \"N\": 10})\n\n    # Calculate the kernel matrix.\n    K_train = gk.fit_transform(G_train)\n    K_test = gk.transform(G_test)\n    end = time()\n\n    # Cross validation on C, variable\n    acc = 0\n    for c in C_grid:\n        # Initialise an SVM and fit.\n        clf = svm.SVC(kernel='precomputed', C=c)\n\n        # Fit on the train Kernel\n        clf.fit(K_train, y_train)\n\n        # Predict and test.\n        y_pred = clf.predict(K_test)\n\n        # Calculate accuracy of classification.\n        acc = max(acc, accuracy_score(y_test, y_pred))\n\n    stats[\"acc\"].append(acc)\n    stats[\"time\"].append(end-start)\n\nprint(\"Mean values of \", niter, \"folds:\")\nprint(\"MLG [Fast] > Accuracy:\",\n      str(round(np.mean(stats[\"acc\"])*100, 2)),\n      \"% | Took:\", sec_to_time(np.mean(stats[\"time\"])))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.15", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}